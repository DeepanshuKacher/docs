{
  "label": "vLLM Endpoint",
  "position": 2,
  "link": {
    "type": "generated-index",
    "description": "Deploy blazingly fast OpenAI-compatible serverless endpoints for any LLM."
  }
}
